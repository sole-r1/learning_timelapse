<!-- <!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>SOLE-R1  </title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <style>
      body {
        margin: 0;
        min-height: 40vh;
        display: flex;
        align-items: center;
        justify-content: center;
        font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI",
          Roboto, Helvetica, Arial, sans-serif;
        background: #0f172a;
        color: #e5e7eb;
        text-align: center;
      }

      .container {
        padding: 2rem;
      }

      h1 {
        font-size: 3rem;
        margin-bottom: 0.5rem;
      }

      p {
        font-size: 1.25rem;
        opacity: 0.85;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>Coming soon! <br>SOLE-R1 model checkpoints, data, video demos, and code will be available here shortly. </h1>
    </div>
  </body>
</html> -->


<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta
      name="description"
      content="SOLE-R1: Video-Language Reasoning as the Sole Reward for On-Robot RL"
    />
    <meta
      name="keywords"
      content="GVL, value learning, vision language models, VLM, robotics, reinforcement learning"
    />
    <!-- <meta
      property="og:image"
      content="https://generative-value-learning.github.io/static/images/icv/method.png"
    /> -->
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>SOLE-R1</title>


    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="SOLE-R1" />
    <meta
      name="twitter:description"
      content=" "
    />
    <!-- <meta
      name="twitter:image"
      content="https://generative-value-learning.github.io/static/images/icv/method.png"
    /> -->

    <link
      href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
      rel="stylesheet"
    />

    <link rel="stylesheet" href="./static/css/bulma.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css" />
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css" />
    <link
      rel="stylesheet"
      href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
    />
    <link rel="stylesheet" href="./static/css/index.css" />

    <!-- <link rel="icon" href="./static/images/favicon.svg" /> -->

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
<style>
body {
  font-family: system-ui;
  /* background: #f5f5f5; */
  background: #white;
  max-width: 1500px;
  margin: 2rem auto;
}

h1 {
  text-align: center;

}

.video-block {
  background: white;
  padding: 1rem;
  margin-bottom: 2rem;
  border-radius: 12px;
}

video {
  width: 100%;
  margin-top: .5rem;
}

.description {
  font-size: 1.1em;
  margin-bottom: .3rem;
}

/* video::-webkit-media-controls {
  display: none !important;
}

video::-webkit-media-controls-panel {
  display: none !important;
}

video::-webkit-media-controls-overlay-play-button {
  display: none !important;
} */

/* video {
  filter: brightness(1.001);
} */
 video::-webkit-media-controls-panel {
  background-image: none !important;
  background-color: transparent !important;
}

video::-webkit-media-controls-enclosure {
  background-image: none !important;
  background-color: transparent !important;
}

video::-webkit-media-controls-overlay-enclosure {
  background-image: none !important;
  background-color: transparent !important;
}

/* Optional: helps avoid a “tinted” look if Chrome blends with page bg */
video {
  background: #000;
}
</style>
</head>

<body>

    <section>
      <!-- <h1 style="font-size:30px;font-weight: bold;">SOLE-R1: Video-Language Reasoning as the Sole Reward for On-Robot RL</h1> -->
      <h1>
                    <!-- <span class="link-block">
                    <a target="_blank" href="https://arxiv.org/abs/2508.01943"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                            <i class="ai ai-arxiv"></i>
                        </span>
                        <span>arXiv</span>
                    </a>
                </span> -->
                  <!-- <span class="link-block">
                    <a
                      href="https://sole-r1.github.io/"
                      target="_blank"
                      class="external-link button is-normal is-rounded is-dark"
                    >
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code & Data (coming soon!)</span>
                    </a>
                  </span> -->
      </h1>
      <br>
      <br>
      <br>
    </section>
    <section>
      <!-- <h2 style="font-size:20px;">We are continuing to add more examples to this site. Example videos below show SOLE-R1 frame-level reasoning and progress prediction for the zero-shot online RL experiments. <br> -->
        <!-- Also, to more clearly illustrate what the outputs of our video and reasoning synthesis approach look like (to generate SOLE-R1 training data), we provide video demonstrations at: <a href="https://sole-r1.github.io/synthesized_video_reasoning_examples/" target="_blank">https://sole-r1.github.io/synthesized_video_reasoning_examples/</a></h2> -->

      <!-- <h4 style="font-weight: normal">The baseline method is the best existing in-context learning framework for video reasoning in embodied settings, <a href="https://generative-value-learning.github.io" target="_blank">GVL (https://generative-value-learning.github.io)</a>.</h4> -->
      <!-- <h4 style="font-weight: normal">There are a total of 142 example videos across 27 tasks. The videos are separated into levels based on the amount of the task completed during the video. The amount of non-expert behavior in the video increases as the level decreases. The highest-level trajectories for each task show full task completion with near-expert behavior. The level 1 trajectories do not achieve any part of the task. -->
        <!-- The task progress values generated by SOLE-R1 and GVL are shown in yellow and blue, respectively. The ground-truth progress values are shown in gray.  -->
        <!-- <br><br> -->
      <!-- </h4> -->
      <br>

<div id="video-container"></div>
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>
<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>

<script>

const videoDescriptions = {

'q3vl8b_1129b_sftv2_lr1e5_eb48_85000_v2_pt3b_mscube_switchview_interp10_20260112_194227_concatenated_timelapse2_web.mp4': 'Pick up the cube from the table.',
'gemini_25_pro_v2_pt3b_mscube_20260115_020333_concatenated_timelapse2_web.mp4': 'Pull the cube into the target area.',

};
const videoModels = {

'q3vl8b_1129b_sftv2_lr1e5_eb48_85000_v2_pt3b_mscube_switchview_interp10_20260112_194227_concatenated_timelapse2_web.mp4': 'SOLE-R1',
'gemini_25_pro_v2_pt3b_mscube_20260115_020333_concatenated_timelapse2_web.mp4': 'Gemini 3 Pro',

};


const videoFiles = [
'q3vl8b_1129b_sftv2_lr1e5_eb48_85000_v2_pt3b_mscube_switchview_interp10_20260112_194227_concatenated_timelapse2_web.mp4',
'gemini_25_pro_v2_pt3b_mscube_20260115_020333_concatenated_timelapse2_web.mp4',
];

const container = document.getElementById("video-container");

videoFiles.forEach(file => {
  const block = document.createElement("div");
  block.className = "video-block";

  const desc = document.createElement("p");
  desc.className = "description";
  desc.model = videoModels[file] || "";
  desc.textContent = videoDescriptions[file] || "No description available.";
  desc.textContent = "Goal: " + desc.textContent
  desc.textContent = desc.model + " (" + desc.textContent + ")";

  const video = document.createElement("video");
  // video.controls = true;
  video.setAttribute("controls", "");
  video.setAttribute("controlslist", "nodownload nofullscreen noremoteplayback");
  video.disablePictureInPicture = true;

  // video.controls = false;
  // video.autoplay = false;
  // video.playsInline = true;
  // video.disablePictureInPicture = true;
  // video.controlsList = "nodownload nofullscreen noremoteplayback";
  
  const source = document.createElement("source");
  source.src = "videos/"+file;
  source.type = "video/mp4";

  video.appendChild(source);

  // block.appendChild(desc.model);
  block.appendChild(desc);
  block.appendChild(video);
  container.appendChild(block);
});
</script>

</body>
</html>
